{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGORITHMIC FLOW TO PARSE CURRENCY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import img2pdf\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import io\n",
    "from google.cloud import vision\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.path.join(os.path.dirname( \"__file__\" ), '..'))\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\", \"aligned_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images_paths = [os.path.join(DATA_DIR, file) for file in os.listdir(DATA_DIR) \n",
    "                       if file.endswith(\".jpg\") or file.endswith(\".png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_images = [cv2.imread(img_path) for img_path in list_of_images_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract OCR results of Google Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_texts(symbols):\n",
    "    text = \"\"\n",
    "    for symbol in symbols:\n",
    "        text += symbol.text\n",
    "    return text \n",
    "\n",
    "def get_document_bounds(image_file):\n",
    "    \"\"\"\n",
    "    Returns document bounds given an image.\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    bounds = []\n",
    "    texts = []\n",
    "\n",
    "    with io.open(image_file, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.document_text_detection(image=image, \n",
    "                                              image_context={\"language_hints\": [\"bn\"]})\n",
    "    document = response.full_text_annotation\n",
    "\n",
    "    # Collect word level bounds by enumerating all document features\n",
    "    for page in document.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    bounds.append(word.bounding_box)\n",
    "                    texts.append(merge_texts(word.symbols))\n",
    "\n",
    "\n",
    "    # The list `bounds` contains the coordinates of the bounding boxes.\n",
    "    # The list `texts` contains the corresponding texts\n",
    "    return bounds, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/ssl/Downloads/mapping-customers-47a86d6bd7ea.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bounds = []\n",
    "doc_texts = []\n",
    "for n,image_file in enumerate(list_of_images_paths):\n",
    "    bounds, texts = get_document_bounds(image_file)\n",
    "    doc_bounds.append(bounds)\n",
    "    doc_texts.append(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Store the spatial location of each document text in pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Functions to compute positions of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_y(point):\n",
    "    return int((point.top_left_y + point.top_right_y)//2)\n",
    "\n",
    "def compute_bottom_y(point):\n",
    "    return int((point.bottom_left_y + point.bottom_right_y)//2)\n",
    "\n",
    "def compute_left_x(point):\n",
    "    return int((point.top_left_x + point.bottom_left_x)//2)\n",
    "\n",
    "def compute_right_x(point):\n",
    "    return int((point.top_right_x + point.bottom_right_x)//2)\n",
    "\n",
    "def compute_mid_x(point):\n",
    "    mid_x_1 = (point.top_left_x + point.top_right_x)/2\n",
    "    mid_x_2 = (point.bottom_left_x + point.bottom_right_x)/2\n",
    "    mid_x = int((mid_x_1+mid_x_2)//2)\n",
    "    return mid_x\n",
    "\n",
    "def compute_mid_y(point):\n",
    "    mid_y_1 = (point.top_left_y + point.top_right_y)/2\n",
    "    mid_y_2 = (point.bottom_left_y + point.bottom_right_y)/2\n",
    "    mid_y = int((mid_y_1+mid_y_2)//2)\n",
    "    return mid_y\n",
    "\n",
    "def compute_height(point):\n",
    "    height_1 = point.bottom_left_y - point.top_left_y\n",
    "    height_2 = point.bottom_right_y - point.top_right_y\n",
    "    height = int((height_1+height_2)//2)\n",
    "    return height\n",
    "\n",
    "def compute_width(point):\n",
    "    widht_1 = point.top_right_x - point.top_left_x\n",
    "    widht_2 = point.bottom_right_x - point.bottom_left_x\n",
    "    widht = int((widht_1+widht_2)//2)\n",
    "    return widht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dfs = []\n",
    "for texts, bounds in zip(doc_texts,doc_bounds):\n",
    "    top_left_x = []\n",
    "    top_left_y = []\n",
    "    top_right_x = []\n",
    "    top_right_y = []\n",
    "    bottom_right_x = []\n",
    "    bottom_right_y = []\n",
    "    bottom_left_x = []\n",
    "    bottom_left_y = []\n",
    "    for bound in bounds:\n",
    "        top_left_x.append(bound.vertices[0].x)\n",
    "        top_left_y.append(bound.vertices[0].y)\n",
    "        top_right_x.append(bound.vertices[1].x)\n",
    "        top_right_y.append(bound.vertices[1].y)\n",
    "        bottom_right_x.append(bound.vertices[2].x)\n",
    "        bottom_right_y.append(bound.vertices[2].y)\n",
    "        bottom_left_x.append(bound.vertices[3].x)\n",
    "        bottom_left_y.append(bound.vertices[3].y)\n",
    "    df = pd.DataFrame({\"word\": texts,\n",
    "                       \"top_left_x\":top_left_x,\n",
    "                       \"top_left_y\":top_left_y,\n",
    "                       \"top_right_x\":top_right_x,\n",
    "                       \"top_right_y\":top_right_y,\n",
    "                       \"bottom_right_x\":bottom_right_x,\n",
    "                       \"bottom_right_y\":bottom_right_y,\n",
    "                       \"bottom_left_x\":bottom_left_x,\n",
    "                       \"bottom_left_y\":bottom_left_y})\n",
    "    \n",
    "    df[\"top_y\"] = df.apply(compute_top_y, axis = 1)\n",
    "    df[\"bottom_y\"] = df.apply(compute_bottom_y, axis = 1)\n",
    "    df[\"left_x\"] = df.apply(compute_left_x, axis = 1)\n",
    "    df[\"right_x\"] = df.apply(compute_right_x, axis = 1)\n",
    "    df[\"mid_x\"] = df.apply(compute_mid_x, axis = 1)\n",
    "    df[\"mid_y\"] = df.apply(compute_mid_y, axis = 1)\n",
    "    df[\"height\"] = df.apply(compute_height, axis = 1)\n",
    "    df[\"width\"] = df.apply(compute_width, axis = 1)\n",
    "    doc_dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parse total amount of document from pandas df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Functions containing algorithmic flow to parse total from pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_total_word(point, search_word_list = [\"total\", \"amount\"]):\n",
    "    if point.word.lower() in search_word_list:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def filter_nearby_words(point, y_upper_limit, y_lower_limit, x_lower_limit):\n",
    "    if point.mid_y>= y_upper_limit and point.mid_y<=y_lower_limit and point.right_x>x_lower_limit:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def compute_distance(point,x1,y1):\n",
    "    x2 = point.mid_x\n",
    "    y2 = point.mid_y\n",
    "    return math.sqrt(((x2-x1)**2)+((y2-y1)**2))\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString))\n",
    "\n",
    "def search_total_by_word(doc_df, search_word = \"total\"):\n",
    "    \"\"\"\n",
    "    Search total amount in document if it exists\n",
    "    \"\"\"\n",
    "    total_df = doc_df[doc_df.apply(search_total_word,\n",
    "                                   axis = 1)]\n",
    "    bottom_y_max = doc_df.bottom_y.max()\n",
    "    if len(total_df) >= 1:\n",
    "        right_x = int(total_df.iloc[-1].right_x)\n",
    "        mid_x = int(total_df.iloc[-1].mid_x)\n",
    "        mid_y = int(total_df.iloc[-1].mid_y)\n",
    "        top_y = int(total_df.iloc[-1].top_y)\n",
    "        bottom_y = int(total_df.iloc[-1].bottom_y)\n",
    "        height = int(total_df.iloc[-1].height)\n",
    "        width = int(total_df.iloc[-1].width)\n",
    "        x_lower_limit = int(right_x)\n",
    "        y_upper_limit = int(mid_y-0.95*height)\n",
    "        y_lower_limit = int(mid_y+0.95*height)\n",
    "        \n",
    "        if bottom_y>=0.5*bottom_y_max:\n",
    "            search_df = doc_df[doc_df.apply(filter_nearby_words,\n",
    "                                                    args=(y_upper_limit,y_lower_limit,x_lower_limit),\n",
    "                                                    axis = 1)]\n",
    "            if len(search_df) == 0:\n",
    "                return False\n",
    "            search_df[\"dist\"] = search_df.apply(compute_distance,\n",
    "                                                args=(mid_x,mid_y),\n",
    "                                                axis = 1)\n",
    "            search_df = search_df.sort_values(\"dist\")\n",
    "            total = False\n",
    "            for row in search_df.iterrows():\n",
    "                word = row[1].word\n",
    "                if hasNumbers(str(word)):\n",
    "                    total = str(word)\n",
    "            return total\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    return False\n",
    "    \n",
    "def search_total(doc_df):\n",
    "    result = search_total_by_word(doc_df)\n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Display the results of invoice corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: local_14.jpg | Total:35,518.35\n",
      "Filename: local_11.jpg | Total not found\n",
      "Filename: local_9.jpg | Total:50,161.00\n",
      "Filename: local_1.jpg | Total:1,450.00\n",
      "Filename: local_2.jpg | Total:357,075.53\n",
      "Filename: local_4.jpg | Total:65,000.00\n",
      "Filename: local_6.jpg | Total:56,700.00\n",
      "Filename: local_10.jpg | Total:136,535.00\n",
      "Filename: loval_7.jpg | Total:1,558,904.00\n",
      "Filename: net_1.png | Total:154.06\n",
      "Filename: local_15.jpg | Total:168,819.00\n",
      "Filename: local_13.jpg | Total:6,300.00\n",
      "Filename: local_8.jpg | Total:8,004.00\n",
      "Filename: local_12.jpg | Total:1,555,902.00\n",
      "Filename: local_5.jpg | Total:79,610.00\n",
      "Filename: local_3.jpg | Total:47,500.00\n"
     ]
    }
   ],
   "source": [
    "for doc_df, path in zip(doc_dfs, list_of_images_paths):\n",
    "    result = search_total(doc_df)\n",
    "    if result:\n",
    "        print(\"Filename: {} | Total:{}\".format(path.split(\"/\")[-1],result))\n",
    "    else:\n",
    "        print(\"Filename: {} | Total not found\".format(path.split(\"/\")[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
